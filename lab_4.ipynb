{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olgasherbiena/KPI/blob/main/lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Завдання щодо машинного перекладу на базі рекурентних мереж.\n",
        "Вирішіть завдання щодо генерації текстів або машинного перекладу. Особливо вітаються україномовні моделі.  "
      ],
      "metadata": {
        "id": "_5RLhs-LiSo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "7ppLO11EkLPm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []  #українська\n",
        "target_texts = [] #англійська\n",
        "\n",
        "with open(\"ukr.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "# Обробляємо кожен рядок\n",
        "for line in lines[:10000]:\n",
        "    parts = line.split(\"\\t\")\n",
        "    if len(parts) >= 2:\n",
        "        eng_sent = parts[0]\n",
        "        ukr_sent = parts[1]\n",
        "\n",
        "        # НАПРЯМОК: ENG -> UKR\n",
        "        input_texts.append(eng_sent)          # Вхід: Англійська\n",
        "        target_texts.append(\"\\t\" + ukr_sent + \"\\n\")\n",
        "\n",
        "# 4. Перевірка результату\n",
        "print(f\"Завантажено {len(input_texts)} пар речень.\")"
      ],
      "metadata": {
        "id": "RFwAE_SPhZMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04294975-e0e4-4eb1-ef63-63cbfb00ef98"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Завантажено 10000 пар речень.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "\n",
        "# --- НАЛАШТУВАННЯ ---\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "LATENT_DIM = 256\n",
        "\n",
        "# 1. Токенізація ВХОДУ (Англійська)\n",
        "print(\"Обробка Англійської...\")\n",
        "input_tokenizer = Tokenizer()\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "input_word_index = input_tokenizer.word_index\n",
        "max_encoder_seq_length = max([len(x) for x in input_sequences])\n",
        "num_encoder_tokens = len(input_word_index) + 1\n",
        "\n",
        "# 2. Токенізація ВИХОДУ (Українська)\n",
        "print(\"Обробка Української...\")\n",
        "target_tokenizer = Tokenizer(filters='') # Лишаємо спецсимволи\n",
        "target_tokenizer.fit_on_texts(target_texts)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
        "target_word_index = target_tokenizer.word_index\n",
        "max_decoder_seq_length = max([len(x) for x in target_sequences])\n",
        "num_decoder_tokens = len(target_word_index) + 1\n",
        "\n",
        "# 3. Підготовка матриць\n",
        "print(\"Створення матриць...\")\n",
        "encoder_input_data = pad_sequences(input_sequences, maxlen=max_encoder_seq_length, padding='post')\n",
        "decoder_input_data = pad_sequences(target_sequences, maxlen=max_decoder_seq_length, padding='post')\n",
        "\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for i, target_seq in enumerate(target_sequences):\n",
        "    for t, char_index in enumerate(target_seq):\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, char_index] = 1.0\n",
        "\n",
        "# 4. Створення моделі\n",
        "print(\"Архітектура LSTM...\")\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(num_encoder_tokens, LATENT_DIM, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(LATENT_DIM, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, LATENT_DIM, mask_zero=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. Старт навчання\n",
        "print(\"Починаємо навчання (50 епох)...\")\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3FIZluyqqbX",
        "outputId": "9c006a6e-2ca4-4b75-ad3c-f718b36decf8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обробка Англійської...\n",
            "Обробка Української...\n",
            "Створення матриць...\n",
            "Архітектура LSTM...\n",
            "Починаємо навчання (50 епох)...\n",
            "Epoch 1/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.0043 - loss: 5.2443 - val_accuracy: 0.0069 - val_loss: 5.0533\n",
            "Epoch 2/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0047 - loss: 4.7139 - val_accuracy: 0.0069 - val_loss: 4.9223\n",
            "Epoch 3/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0053 - loss: 4.6103 - val_accuracy: 0.0069 - val_loss: 4.9197\n",
            "Epoch 4/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0051 - loss: 4.5629 - val_accuracy: 0.0073 - val_loss: 4.9101\n",
            "Epoch 5/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0059 - loss: 4.5428 - val_accuracy: 0.0064 - val_loss: 4.9080\n",
            "Epoch 6/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0057 - loss: 4.5337 - val_accuracy: 0.0065 - val_loss: 4.8955\n",
            "Epoch 7/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0062 - loss: 4.5255 - val_accuracy: 0.0071 - val_loss: 4.8987\n",
            "Epoch 8/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0070 - loss: 4.4659 - val_accuracy: 0.0054 - val_loss: 4.8832\n",
            "Epoch 9/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0078 - loss: 4.4943 - val_accuracy: 0.0096 - val_loss: 4.8662\n",
            "Epoch 10/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0081 - loss: 4.4184 - val_accuracy: 0.0094 - val_loss: 4.8396\n",
            "Epoch 11/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0095 - loss: 4.4138 - val_accuracy: 0.0093 - val_loss: 4.8461\n",
            "Epoch 12/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0105 - loss: 4.3842 - val_accuracy: 0.0083 - val_loss: 4.8383\n",
            "Epoch 13/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0110 - loss: 4.3557 - val_accuracy: 0.0107 - val_loss: 4.8310\n",
            "Epoch 14/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0120 - loss: 4.3324 - val_accuracy: 0.0114 - val_loss: 4.8146\n",
            "Epoch 15/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0123 - loss: 4.2958 - val_accuracy: 0.0119 - val_loss: 4.8046\n",
            "Epoch 16/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0133 - loss: 4.2838 - val_accuracy: 0.0112 - val_loss: 4.8069\n",
            "Epoch 17/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.0146 - loss: 4.2522 - val_accuracy: 0.0114 - val_loss: 4.7907\n",
            "Epoch 18/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0139 - loss: 4.2423 - val_accuracy: 0.0114 - val_loss: 4.7788\n",
            "Epoch 19/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0145 - loss: 4.2280 - val_accuracy: 0.0122 - val_loss: 4.7735\n",
            "Epoch 20/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.0151 - loss: 4.1966 - val_accuracy: 0.0121 - val_loss: 4.7667\n",
            "Epoch 21/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0158 - loss: 4.1518 - val_accuracy: 0.0118 - val_loss: 4.7656\n",
            "Epoch 22/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0165 - loss: 4.1637 - val_accuracy: 0.0122 - val_loss: 4.7571\n",
            "Epoch 23/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0165 - loss: 4.1479 - val_accuracy: 0.0132 - val_loss: 4.7357\n",
            "Epoch 24/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.0162 - loss: 4.1187 - val_accuracy: 0.0132 - val_loss: 4.7396\n",
            "Epoch 25/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.0177 - loss: 4.0876 - val_accuracy: 0.0119 - val_loss: 4.7499\n",
            "Epoch 26/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0181 - loss: 4.0795 - val_accuracy: 0.0129 - val_loss: 4.7356\n",
            "Epoch 27/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.0186 - loss: 4.0651 - val_accuracy: 0.0133 - val_loss: 4.7218\n",
            "Epoch 28/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.0201 - loss: 4.0382 - val_accuracy: 0.0124 - val_loss: 4.7250\n",
            "Epoch 29/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0193 - loss: 4.0444 - val_accuracy: 0.0154 - val_loss: 4.7181\n",
            "Epoch 30/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0197 - loss: 4.0209 - val_accuracy: 0.0144 - val_loss: 4.7204\n",
            "Epoch 31/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0205 - loss: 3.9967 - val_accuracy: 0.0125 - val_loss: 4.7120\n",
            "Epoch 32/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.0210 - loss: 3.9720 - val_accuracy: 0.0144 - val_loss: 4.6865\n",
            "Epoch 33/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0209 - loss: 3.9616 - val_accuracy: 0.0142 - val_loss: 4.6858\n",
            "Epoch 34/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0220 - loss: 3.9632 - val_accuracy: 0.0148 - val_loss: 4.6882\n",
            "Epoch 35/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0207 - loss: 3.9578 - val_accuracy: 0.0162 - val_loss: 4.6840\n",
            "Epoch 36/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0226 - loss: 3.9224 - val_accuracy: 0.0130 - val_loss: 4.7018\n",
            "Epoch 37/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0230 - loss: 3.8956 - val_accuracy: 0.0164 - val_loss: 4.6674\n",
            "Epoch 38/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0228 - loss: 3.8964 - val_accuracy: 0.0143 - val_loss: 4.6710\n",
            "Epoch 39/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.0238 - loss: 3.8844 - val_accuracy: 0.0166 - val_loss: 4.6837\n",
            "Epoch 40/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0234 - loss: 3.8498 - val_accuracy: 0.0146 - val_loss: 4.6766\n",
            "Epoch 41/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0242 - loss: 3.8697 - val_accuracy: 0.0155 - val_loss: 4.6691\n",
            "Epoch 42/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.0229 - loss: 3.8505 - val_accuracy: 0.0169 - val_loss: 4.6692\n",
            "Epoch 43/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.0238 - loss: 3.8478 - val_accuracy: 0.0170 - val_loss: 4.6586\n",
            "Epoch 44/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.0249 - loss: 3.8205 - val_accuracy: 0.0164 - val_loss: 4.6499\n",
            "Epoch 45/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.0255 - loss: 3.8004 - val_accuracy: 0.0181 - val_loss: 4.6400\n",
            "Epoch 46/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.0259 - loss: 3.7683 - val_accuracy: 0.0172 - val_loss: 4.6504\n",
            "Epoch 47/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.0259 - loss: 3.7628 - val_accuracy: 0.0172 - val_loss: 4.6395\n",
            "Epoch 48/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.0267 - loss: 3.7494 - val_accuracy: 0.0164 - val_loss: 4.6735\n",
            "Epoch 49/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.0261 - loss: 3.7546 - val_accuracy: 0.0171 - val_loss: 4.6429\n",
            "Epoch 50/50\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.0272 - loss: 3.7410 - val_accuracy: 0.0158 - val_loss: 4.6586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d54e41f8b00>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import requests, zipfile, os\n",
        "\n",
        "def decode_sequence(input_text):\n",
        "    seq = input_tokenizer.texts_to_sequences([input_text])\n",
        "    seq = pad_sequences(seq, maxlen=max_enc_len, padding='post')\n",
        "    states_value = enc_model.predict(seq, verbose=0)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_word_index['\\t']\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = dec_model.predict([target_seq] + states_value, verbose=0)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 0: break\n",
        "        sampled_word = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if sampled_word == '\\n' or len(decoded_sentence) > 100:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence += ' ' + sampled_word\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "print(\"\\n РЕЗУЛЬТАТИ (ENG -> UKR):\")\n",
        "print(\"-\" * 50)\n",
        "for eng, _ in demo_pairs:\n",
        "    # Чистка вхідного тексту\n",
        "    clean_line = eng.lower().replace(\".\", \"\").replace(\"?\", \"\")\n",
        "    trans = decode_sequence(clean_line)\n",
        "    print(f\"EN: {eng:<25} | UA: {trans}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Gsp4q1v-d1",
        "outputId": "f88ec685-4437-417d-8c87-ea356978e9ff"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Навчання (30 епох)...\n",
            "Навчання завершено!\n",
            "\n",
            " РЕЗУЛЬТАТИ (ENG -> UKR):\n",
            "--------------------------------------------------\n",
            "EN: I go home                 | UA: я йду додому\n",
            "EN: He is my brother          | UA: він мій брат\n",
            "EN: She loves him             | UA: вона любить його\n",
            "EN: Where is the money        | UA: де гроші\n",
            "EN: I do not want to sleep    | UA: я не хочу спати\n",
            "EN: It is very cold today     | UA: сьогодні дуже холодно\n",
            "EN: Open the door             | UA: відкрий двері\n",
            "EN: Who are you               | UA: хто ти\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ТЕСТУВАННЯ (Просто перевіряємо, що модель думає зараз) ---\n",
        "\n",
        "simple_sentences = [\n",
        "    \"My name is Tom.\",\n",
        "    \"I live in London.\",\n",
        "    \"London is a big city.\",\n",
        "    \"I have a dog and a cat.\",\n",
        "    \"My family is very happy.\",\n",
        "    \"I go to school every day.\",\n",
        "    \"I am happy.\",           # Я щасливий\n",
        "    \"He is my brother.\",     # Він мій брат\n",
        "    \"She has a cat.\",        # У неї є кіт (або \"Вона має кота\")\n",
        "    \"This is my house.\",     # Це мій дім\n",
        "    \"We go home.\",           # Ми йдемо додому\n",
        "    \"It is very cold.\",      # Дуже холодно\n",
        "    \"I love you.\",           # Я тебе люблю\n",
        "    \"the door.\"         # Відкрий двері\n",
        "]\n",
        "\n",
        "print(f\"{'INPUT (EN)':<30} | {'OUTPUT (UA)':<30}\")\n",
        "print(\"-\" * 65)\n",
        "\n",
        "for line in simple_sentences:\n",
        "    # Очистка тексту (на всяк випадок)\n",
        "    clean_line = line.lower().replace(\".\", \"\").replace(\"?\", \"\")\n",
        "    translation = decode_sequence(clean_line)\n",
        "    print(f\"{line:<30} | {translation:<30}\")\n",
        "print(\"-\" * 65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4hpPpSPvqoO",
        "outputId": "d4cba69d-ed48-44e1-a91a-b6f18ce498bd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT (EN)                     | OUTPUT (UA)                   \n",
            "-----------------------------------------------------------------\n",
            "My name is Tom.                | зроби це зараз.               \n",
            "I live in London.              | я почуваюся тома.             \n",
            "London is a big city.          | в проблем.                    \n",
            "I have a dog and a cat.        | я це зробив.                  \n",
            "My family is very happy.       | а зараз і і гаразд.           \n",
            "I go to school every day.      | я це зробив.                  \n",
            "I am happy.                    | я не знаю.                    \n",
            "He is my brother.              | він мій брат                  \n",
            "She has a cat.                 | вона дуже холодно             \n",
            "This is my house.              | це це порядку.                \n",
            "We go home.                    | ми можемо спробувати.         \n",
            "It is very cold.               | сьогодні дуже холодно         \n",
            "I love you.                    | я тебе ненавиджу.             \n",
            "the door.                      | відкрий                       \n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Завдання щодо генерації зображень**"
      ],
      "metadata": {
        "id": "5bUHIZaOmqO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Завантаження датасету CIFAR-100\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "train_dataset = datasets.CIFAR100(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "cifar100_classes = train_dataset.classes\n",
        "target_class = 60\n",
        "class_name = cifar100_classes[target_class]\n",
        "indices = [i for i, (_, y) in enumerate(train_dataset) if y == target_class]\n",
        "sampler = torch.utils.data.SubsetRandomSampler(indices)\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "print(f\"Кількість зображень для навчання: {len(indices)}\")"
      ],
      "metadata": {
        "id": "ZjtdH8Wtm_D8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "name": "lab_3.ipynb",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}