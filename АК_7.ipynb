{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olgasherbiena/KPI/blob/main/%D0%90%D0%9A_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n"
      ],
      "metadata": {
        "id": "ABND7PIbPhQW",
        "outputId": "62e10996-f273-4d3d-8db8-775705792172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import kagglehub\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "csv_path  = kagglehub.dataset_download(\"shantanudhakadd/email-spam-detection-dataset-classification\")\n",
        "csv_file = os.path.join(csv_path, 'spam.csv')\n",
        "df = pd.read_csv(csv_file, encoding='latin1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m74dbY160h4m",
        "outputId": "f5c49d9b-49db-499c-8ea4-2cdb6f13aa1f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'email-spam-detection-dataset-classification' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['v1', 'v2']].copy()\n",
        "df.columns = ['label', 'text']\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbfNf6aCGIDA",
        "outputId": "b2d3f465-6f1b-4c07-e9d3-0153945ed52d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n",
            "label\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LSH:\n",
        "    def __init__(self, num_buckets, num_hash_functions, input_dim):\n",
        "        self.num_buckets = num_buckets\n",
        "        self.num_hash_functions = num_hash_functions\n",
        "        self.input_dim = input_dim\n",
        "        self.hash_functions = [self._generate_hash_function() for _ in range(num_hash_functions)]\n",
        "        self.buckets = {i: [] for i in range(num_buckets)}\n",
        "\n",
        "    def _generate_hash_function(self):\n",
        "        return np.random.randn(self.input_dim)\n",
        "\n",
        "    def hash(self, vector):\n",
        "        hashes = []\n",
        "        for hash_function in self.hash_functions:\n",
        "            hash_value = np.dot(vector, hash_function)\n",
        "            hash_value = hash_value / np.linalg.norm(hash_function)\n",
        "            hash_value = hash_value.astype(int)\n",
        "            hashes.append(hash_value)\n",
        "        return hashes\n",
        "\n",
        "    def add_vector(self, vector):\n",
        "        hashes = self.hash(vector)\n",
        "        for i, hash_value in enumerate(hashes):\n",
        "            self.buckets[hash_value % self.num_buckets].append((i, vector))\n",
        "\n",
        "    def query(self, query_vector):\n",
        "        query_hashes = self.hash(query_vector)\n",
        "        similar_items = []\n",
        "        for hash_value in query_hashes:\n",
        "            bucket = self.buckets[hash_value % self.num_buckets]\n",
        "            for item in bucket:\n",
        "                if np.array_equal(item[1], query_vector):\n",
        "                    continue\n",
        "                if not any(np.array_equal(item[1], sim[1]) for sim in similar_items):\n",
        "                    similar_items.append(item)\n",
        "        return similar_items\n"
      ],
      "metadata": {
        "id": "yJiRQTFEI6rE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['text'])  # 'text' — колонка з email\n",
        "X_dense = X.toarray()  # перетворюємо в звичайний numpy array"
      ],
      "metadata": {
        "id": "w3Wk-jftUxGq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsh = LSH(num_buckets=10, num_hash_functions=5, input_dim=X_dense.shape[1])\n",
        "for vec in X_dense:\n",
        "    lsh.add_vector(vec)\n",
        "query_vec = X_dense[0]\n",
        "similar_items = lsh.query(query_vec)\n",
        "print(\"Схожі об'єкти:\", len(similar_items))"
      ],
      "metadata": {
        "id": "NGQc4LdfU4Gl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "АК_7",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}